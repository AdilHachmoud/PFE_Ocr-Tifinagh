{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abderrazzaq-laanoui/PFE-HexaCoders/blob/PreparingData/ml_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hCO76eiaTU"
      },
      "source": [
        "<div style=\"text-align:center\"><h1>RECONNAISSANCE DE L'ÉCRITURE MANUSCRITE DE LESTTRES TEFINAGH</h1></div>\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CACEY3QXpYdB"
      },
      "source": [
        "# DEPANDECIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiufKkBMpkLy"
      },
      "source": [
        "#### Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrxPNHSdpikm",
        "outputId": "77b99f2c-d305-4572-c45b-5cc593847b28"
      },
      "source": [
        "# liaison avec  Google Drive comme source de donnees \r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puJQ-cszpuEL"
      },
      "source": [
        "#### importations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDPSleVSptAh"
      },
      "source": [
        "# Importation des bibliothèques\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2 as cv\r\n",
        "import random\r\n",
        "import pickle\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import time\r\n",
        "from datetime import timedelta\r\n",
        "import math\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_8SKXLvwgFA"
      },
      "source": [
        "#### Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYOaYFjlwlDU"
      },
      "source": [
        "\r\n",
        "CATEGORIES = [\"ya\", \"yab\", \"yach\", \"yad\", \"yadd\", \"yae\", \"yaf\", \"yag\", \"yagh\", \r\n",
        "              \"yagw\", \"yah\", \"yahh\", \"yaj\", \"yak\", \"yakw\", \"yal\", \"yam\", \"yan\", \r\n",
        "              \"yaq\", \"yar\",\"yarr\", \"yas\", \"yass\", \"yat\", \"yatt\", \"yaw\", \"yax\", \r\n",
        "              \"yay\", \"yaz\", \"yazz\", \"yey\", \"yi\", \"yu\"] # a list of all possible classes\r\n",
        "T_CATEGORIES = ['ⴰ', 'ⴱ', 'ⵛ', 'ⴷ', 'ⴹ', 'ⵄ', 'ⴼ', 'ⴳ', 'ⵖ', 'ⴳⵯ', 'ⵀ', 'ⵃ', 'ⵊ', 'ⴽ', 'ⴽⵯ',\r\n",
        "                'ⵍ','ⵎ','ⵏ', 'ⵇ', 'ⵔ', 'ⵕ', 'ⵙ', 'ⵚ', 'ⵜ', 'ⵟ', 'ⵡ', 'ⵅ', 'ⵢ', 'ⵣ','ⵥ', 'ⴻ', 'ⵉ', 'ⵓ']\r\n",
        "\r\n",
        "training_data = [] # cette liste qui contiendra les données d'entraînement traitées\r\n",
        "testing_data = [] # cette liste qui contiendra les données de test traitées"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp2YMmNBHo0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4e4bead-edd2-459d-eba8-4591ea60d23f"
      },
      "source": [
        "for i in range(33):\r\n",
        "    print(CATEGORIES[i] + ' => ' + T_CATEGORIES[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ya => ⴰ\n",
            "yab => ⴱ\n",
            "yach => ⵛ\n",
            "yad => ⴷ\n",
            "yadd => ⴹ\n",
            "yae => ⵄ\n",
            "yaf => ⴼ\n",
            "yag => ⴳ\n",
            "yagh => ⵖ\n",
            "yagw => ⴳⵯ\n",
            "yah => ⵀ\n",
            "yahh => ⵃ\n",
            "yaj => ⵊ\n",
            "yak => ⴽ\n",
            "yakw => ⴽⵯ\n",
            "yal => ⵍ\n",
            "yam => ⵎ\n",
            "yan => ⵏ\n",
            "yaq => ⵇ\n",
            "yar => ⵔ\n",
            "yarr => ⵕ\n",
            "yas => ⵙ\n",
            "yass => ⵚ\n",
            "yat => ⵜ\n",
            "yatt => ⵟ\n",
            "yaw => ⵡ\n",
            "yax => ⵅ\n",
            "yay => ⵢ\n",
            "yaz => ⵣ\n",
            "yazz => ⵥ\n",
            "yey => ⴻ\n",
            "yi => ⵉ\n",
            "yu => ⵓ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT29UQrnd5G0"
      },
      "source": [
        "# LOADING UP THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4_nyb6goN6"
      },
      "source": [
        "\r\n",
        "#@markdown \\\r\n",
        "#@markdown #### Entrez le chemin d'accès au répertoire DATASET dans votre Drive:\r\n",
        "chemin = \"\" #@param {type:\"string\"}\r\n",
        "#@markdown \\\r\n",
        "\r\n",
        "if chemin == \"\":\r\n",
        "    chemin = \"genie info/Rapport PFE - HexaCoders/DATASET\" #default path\r\n",
        "# Declaration des Variables\r\n",
        "DIR = os.path.join(\"/content/drive/MyDrive\",chemin) # h the path to the DATASET dir  in your drive\r\n",
        "TRAIN_DATA_DIR = os.path.join(DIR,\"training_data/\")\r\n",
        "TEST_DATA_DIR = os.path.join(DIR,\"testing_data/\")\r\n",
        "MODEL_DIR = os.path.join(DIR,\"model/\")\r\n",
        "TRAIN_MODEL_DIR = os.path.join(DIR,\"model/train/\")\r\n",
        "TEST_MODEL_DIR = os.path.join(DIR,\"model/test/\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdc2JFHU77S7"
      },
      "source": [
        "## TRAINING DATA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N_yFjf_qXCP"
      },
      "source": [
        "#### Preparing  data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S-Vd6uGsYcO"
      },
      "source": [
        "<b>OpenCV</b> (référencé par cv) est une bibliothèque multi-plateforme qui nous permet de développer des applications de vision par ordinateur en temps réel. Elle se concentre principalement sur le traitement des images en temps réel., la capture et l'analyse vidéo, y compris des fonctionnalités telles que la détection des visages et des objets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTDF8xVxkhrs"
      },
      "source": [
        "training_data = [] # la liste qui contiendra les données d'entraînement traitées\r\n",
        "def prepare_training_data():\r\n",
        "    for category in CATEGORIES :\r\n",
        "        path = os.path.join(TRAIN_DATA_DIR, category)\r\n",
        "        class_num = CATEGORIES.index(category)  # obtention du classement (0 à 32)\r\n",
        "        for img in os.listdir(path): # itérer sur chaque image dans un dossier de caractères\r\n",
        "            img_array = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE) # read graysacled images\r\n",
        "            new_array = cv.resize(img_array, (50,50)) # resizing images\r\n",
        "            training_data.append([new_array, class_num]) # append processed image to the training data list\r\n",
        "\r\n",
        "prepare_training_data() # calling the fct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZslzhLOz64Ib"
      },
      "source": [
        "testing_data = [] # a list that will contain processed testing data\r\n",
        "def prepare_testing_data():\r\n",
        "    for category in CATEGORIES :\r\n",
        "        path = os.path.join(TEST_DATA_DIR, category)\r\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 to 32)\r\n",
        "        for img in os.listdir(path): # iterate over each image in a caracter folder \r\n",
        "            img_array = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE) # read graysacled images\r\n",
        "            new_array = cv.resize(img_array, (50,50)) # resizing images\r\n",
        "            testing_data.append([new_array, class_num]) # append processed image to the testing data list\r\n",
        "\r\n",
        "prepare_testing_data() # calling the fct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbCC07Y3coSH"
      },
      "source": [
        "Nous voulons mélanger les données. Pour l'instant, nos données ne sont que \"ya\", puis \"yab\", puis \"yach\" ... . Cela finit généralement par causer des problèmes, car, au début, le classificateur apprendra à prédire toujours \"ya\". Ensuite, il passera à prédire tout \"yab\" ..., Faire des allers-retours comme ça n'est pas bon non plus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4nf3AKE7GDh"
      },
      "source": [
        "# shuffle the  data randomly \r\n",
        "# random.shuffle(training_data)\r\n",
        "random.shuffle(testing_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-_F3RpVwN5d"
      },
      "source": [
        "#### Creating the  model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1vgeaDU7fHa"
      },
      "source": [
        "# Create the model\r\n",
        "x_train = [] \r\n",
        "y_train = []\r\n",
        "\r\n",
        "for features,label in training_data:\r\n",
        "    x_train.append(features)\r\n",
        "    y_train.append(label)\r\n",
        "\r\n",
        "x_train = np.array(x_train)\r\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfg7eK6g88Xg"
      },
      "source": [
        "# Create the model\r\n",
        "x_test = [] \r\n",
        "y_test = []\r\n",
        "\r\n",
        "for features,label in testing_data:\r\n",
        "    x_test.append(features)\r\n",
        "    y_test.append(label)\r\n",
        "\r\n",
        "x_test = np.array(x_test)\r\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeYWj6QXqgeu"
      },
      "source": [
        "#### Saving the  model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4lC8VIOb_kY"
      },
      "source": [
        "Le module <b> pickle </b> met en œuvre des protocoles binaires pour sérialiser et désérialiser une structure d'objet Python. <br><br> Le \"pickling\" est le processus par lequel une hiérarchie d'objets Python est convertie en un flux d'octets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzzQfQdu7rnu"
      },
      "source": [
        "# Saving the model\r\n",
        "\r\n",
        "pickle_out = open(TRAIN_MODEL_DIR + \"x_train.pickle\",\"wb\")\r\n",
        "pickle.dump(x_train, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(TRAIN_MODEL_DIR + \"y_train.pickle\",\"wb\")\r\n",
        "pickle.dump(y_train, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo_g1sU_9Okt"
      },
      "source": [
        "# Saving the model\r\n",
        "\r\n",
        "pickle_out = open(TEST_MODEL_DIR + \"x_test.pickle\",\"wb\")\r\n",
        "pickle.dump(x_test, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(TEST_MODEL_DIR + \"y_test.pickle\",\"wb\")\r\n",
        "pickle.dump(y_test, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9s-a1jwqqQQ"
      },
      "source": [
        "#### Uploading the  model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PRFC3SurZOH"
      },
      "source": [
        "Le \"unpickling\" est l'opération inverse, par laquelle un flux d'octets (provenant d'un fichier binaire ou d'un objet de type octet) est reconverti en une hiérarchie d'objets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8tLrB3_72kp"
      },
      "source": [
        "# to load the model we use the script\r\n",
        "pickle_in = open(TRAIN_MODEL_DIR + \"x_train.pickle\",\"rb\")\r\n",
        "x_train = pickle.load(pickle_in)\r\n",
        "\r\n",
        "pickle_in = open(TRAIN_MODEL_DIR + \"y_train.pickle\",\"rb\")\r\n",
        "y_train = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwSHBy139ayT"
      },
      "source": [
        "# to load the model we use the script\r\n",
        "pickle_in = open(TEST_MODEL_DIR + \"x_test.pickle\",\"rb\")\r\n",
        "x_test = pickle.load(pickle_in)\r\n",
        "\r\n",
        "pickle_in = open(TEST_MODEL_DIR + \"y_test.pickle\",\"rb\")\r\n",
        "y_test = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04UMVpJcIDiv"
      },
      "source": [
        "# CREATING THE CONVOLUTIONAL NURAL NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaQ6iTWVBtzS"
      },
      "source": [
        "#### Helper-function for plotting images\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBcIZgZKBssY"
      },
      "source": [
        "def plot_image(image, cls_true, cls_pred=None):\r\n",
        "\r\n",
        "    plt.imshow(image.reshape(img_shape), cmap='gray')\r\n",
        "    \r\n",
        "    # Show true and predicted classes.\r\n",
        "    if cls_pred is None:\r\n",
        "        plt.figtext(.5,0,\"True: {0}\".format(T_CATEGORIES[cls_true]), fontsize=14, ha='center')\r\n",
        "    else:\r\n",
        "          plt.figtext(.5,0, \"True: {0}, Pred: {1}\".format(T_CATEGORIES[cls_true], T_CATEGORIES[cls_pred]), fontsize=14, ha='center')\r\n",
        "        \r\n",
        "    plt.axis('off')\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM8TPLkXr7Mu"
      },
      "source": [
        "#### CNN Configurations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUp1KS7HxZRD"
      },
      "source": [
        "# Convolutional Layer 1.\r\n",
        "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\r\n",
        "num_filters1 = 16         # There are 16 of these filters.\r\n",
        "\r\n",
        "# Convolutional Layer 2.\r\n",
        "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\r\n",
        "num_filters2 = 36         # There are 36 of these filters.\r\n",
        "\r\n",
        "# Fully-connected layer.\r\n",
        "fc_size = 128             # Number of neurons in fully-connected layer."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I5wu7iWBicv"
      },
      "source": [
        "#### Data-dimensions for convenience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2A6pz5O_l0k"
      },
      "source": [
        "# The number of pixels in each dimension of an image.\r\n",
        "img_size = 50\r\n",
        "\r\n",
        "# The images are stored in one-dimensional arrays of this length.\r\n",
        "img_size_flat = 50*50\r\n",
        "\r\n",
        "# Tuple with height and width of images used to reshape arrays.\r\n",
        "img_shape = (50, 50)\r\n",
        "\r\n",
        "# Number of classes, one class for each of 33 alphabet.\r\n",
        "num_classes = 33\r\n",
        "\r\n",
        "# Number of colour channels for the images: 1 channel for gray-scale.\r\n",
        "num_channels = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKc7mXkVQHP5"
      },
      "source": [
        "#### Strcturing Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k1w_AkRNO5g"
      },
      "source": [
        "# to reduce the computition we convert the numbers from float64 => float32\r\n",
        "# we normalise (deviding all by 255.0) to make numbers between 0 => 1 instead of 0 => 255\r\n",
        "x_train = x_train.reshape(-1,img_size_flat).astype(\"float32\") / 255.0 \r\n",
        "x_test = x_test.reshape(-1,img_size_flat).astype(\"float32\") / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mdH9o_p1zGT"
      },
      "source": [
        "## NN USING TANSERFLOW FRAMEWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPX4jaHR17Rm"
      },
      "source": [
        "#### Sequential API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bu6sWFgaO453",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "37348695-647f-4f92-a9cf-140980cca437"
      },
      "source": [
        "model = keras.Sequential()\r\n",
        "model.add(keras.Input(shape=img_size_flat))\r\n",
        "model.add(layers.Danse(512, activaion='relu'))\r\n",
        "model.add(layers.Danse(256, activaion='relu'))\r\n",
        " model.add(layers.Danse(33))\r\n",
        " \r\n",
        " logits = True"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-5f3ec9641356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2684\u001b[0m       input_spec.assert_input_compatibility(\n\u001b[0;32m-> 2685\u001b[0;31m           self.input_spec, inputs, self.name)\n\u001b[0m\u001b[1;32m   2686\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2687\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype_policy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    237\u001b[0m                          \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                          \u001b[0;34m'. Full shape received: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                          str(tuple(shape)))\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;31m# Check dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input 0 of layer conv2d_2 is incompatible with the layer: : expected min_ndim=4, found ndim=3. Full shape received: (None, 50, 50)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHvCjJH5b2bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5c3504d-da5f-4101-8fac-18178c25e925"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 512)               1280512   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               131328    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 33)                8481      \n",
            "=================================================================\n",
            "Total params: 1,420,321\n",
            "Trainable params: 1,420,321\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWXxX1lU3-Qb"
      },
      "source": [
        "#### Training specifications"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KBh0OmC3Zvk"
      },
      "source": [
        "model.compile(\r\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(),\r\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.001),\r\n",
        "    metrics=[\"accuracy\"],\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETNF0yCQ33zF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "583b905e-1592-42b6-a8eb-ef665d889718"
      },
      "source": [
        "model.fit(x_train, y_train, batch_size=100, epochs=30, verbose=2)\r\n",
        "model.evaluate(x_test, y_test, batch_size=100, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "231/231 - 1s - loss: 3.0547 - accuracy: 0.1919\n",
            "Epoch 2/30\n",
            "231/231 - 0s - loss: 1.3094 - accuracy: 0.6403\n",
            "Epoch 3/30\n",
            "231/231 - 0s - loss: 0.7767 - accuracy: 0.7834\n",
            "Epoch 4/30\n",
            "231/231 - 0s - loss: 0.6501 - accuracy: 0.8106\n",
            "Epoch 5/30\n",
            "231/231 - 0s - loss: 0.5569 - accuracy: 0.8369\n",
            "Epoch 6/30\n",
            "231/231 - 0s - loss: 0.5259 - accuracy: 0.8437\n",
            "Epoch 7/30\n",
            "231/231 - 0s - loss: 0.4806 - accuracy: 0.8571\n",
            "Epoch 8/30\n",
            "231/231 - 0s - loss: 0.4335 - accuracy: 0.8721\n",
            "Epoch 9/30\n",
            "231/231 - 0s - loss: 0.4062 - accuracy: 0.8778\n",
            "Epoch 10/30\n",
            "231/231 - 0s - loss: 0.3834 - accuracy: 0.8833\n",
            "Epoch 11/30\n",
            "231/231 - 0s - loss: 0.3707 - accuracy: 0.8855\n",
            "Epoch 12/30\n",
            "231/231 - 0s - loss: 0.3339 - accuracy: 0.9002\n",
            "Epoch 13/30\n",
            "231/231 - 0s - loss: 0.3279 - accuracy: 0.9017\n",
            "Epoch 14/30\n",
            "231/231 - 0s - loss: 0.3415 - accuracy: 0.8936\n",
            "Epoch 15/30\n",
            "231/231 - 0s - loss: 0.3418 - accuracy: 0.8950\n",
            "Epoch 16/30\n",
            "231/231 - 0s - loss: 0.2868 - accuracy: 0.9110\n",
            "Epoch 17/30\n",
            "231/231 - 0s - loss: 0.3102 - accuracy: 0.9028\n",
            "Epoch 18/30\n",
            "231/231 - 0s - loss: 0.2774 - accuracy: 0.9146\n",
            "Epoch 19/30\n",
            "231/231 - 0s - loss: 0.2722 - accuracy: 0.9151\n",
            "Epoch 20/30\n",
            "231/231 - 0s - loss: 0.2705 - accuracy: 0.9138\n",
            "Epoch 21/30\n",
            "231/231 - 0s - loss: 0.2662 - accuracy: 0.9179\n",
            "Epoch 22/30\n",
            "231/231 - 0s - loss: 0.2368 - accuracy: 0.9246\n",
            "Epoch 23/30\n",
            "231/231 - 0s - loss: 0.2369 - accuracy: 0.9255\n",
            "Epoch 24/30\n",
            "231/231 - 0s - loss: 0.2321 - accuracy: 0.9270\n",
            "Epoch 25/30\n",
            "231/231 - 0s - loss: 0.2316 - accuracy: 0.9257\n",
            "Epoch 26/30\n",
            "231/231 - 0s - loss: 0.2281 - accuracy: 0.9257\n",
            "Epoch 27/30\n",
            "231/231 - 0s - loss: 0.2446 - accuracy: 0.9212\n",
            "Epoch 28/30\n",
            "231/231 - 0s - loss: 0.2376 - accuracy: 0.9242\n",
            "Epoch 29/30\n",
            "231/231 - 0s - loss: 0.2087 - accuracy: 0.9334\n",
            "Epoch 30/30\n",
            "231/231 - 0s - loss: 0.2048 - accuracy: 0.9335\n",
            "27/27 - 0s - loss: 0.2287 - accuracy: 0.9303\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2287461906671524, 0.9303030371665955]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "betRQkh2767Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2cffd06-7dd8-43fd-9b57-93ff64411757"
      },
      "source": [
        "model.save(os.path.join(MODEL_DIR,'Seq.model'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/genie info/Rapport PFE - HexaCoders/DATASET/model/Seq.model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W28LC-UeZcix"
      },
      "source": [
        "model = keras.models.load_model(MODEL_DIR + 'Seq.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mnmHxTyJ_O_U"
      },
      "source": [
        "def prepare_input(path): \r\n",
        "    img_array = cv.imread(path, cv.IMREAD_GRAYSCALE) # read graysacled images\r\n",
        "    input = cv.resize(img_array, img_shape) # resizing images\r\n",
        "    return input.reshape( -1,img_size_flat)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFzl_XZLDbQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3da4b9f2-2f53-4bb4-f97e-e7aa39c3a556"
      },
      "source": [
        "prediction = model.predict(prepare_input('pred10.jpeg'))\r\n",
        "print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y-ZPldFciIY"
      },
      "source": [
        "* pred7\r\n",
        "\r\n",
        "\r\n"
      ]
    }
  ]
}