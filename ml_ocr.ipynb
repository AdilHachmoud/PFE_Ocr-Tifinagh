{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abderrazzaq-laanoui/PFE-HexaCoders/blob/PreparingData/ml_ocr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hCO76eiaTU"
      },
      "source": [
        "<div style=\"text-align:center\"><h1>RECONNAISSANCE DE L'ÉCRITURE MANUSCRITE DE LESTTRES TEFINAGH</h1></div>\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CACEY3QXpYdB"
      },
      "source": [
        "# DEPANDECIES"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiufKkBMpkLy"
      },
      "source": [
        "#### Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrxPNHSdpikm",
        "outputId": "694068a4-d91c-409a-c5bb-6c331978298a"
      },
      "source": [
        "# mount Google Drive\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puJQ-cszpuEL"
      },
      "source": [
        "#### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDPSleVSptAh"
      },
      "source": [
        "# Import libraries\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2 as cv\r\n",
        "import random\r\n",
        "import pickle\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import time\r\n",
        "from datetime import timedelta\r\n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_8SKXLvwgFA"
      },
      "source": [
        "#### Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYOaYFjlwlDU"
      },
      "source": [
        "\r\n",
        "CATEGORIES = [\"ya\", \"yab\", \"yach\", \"yad\", \"yadd\", \"yae\", \"yaf\", \"yag\", \"yagh\", \r\n",
        "              \"yagw\", \"yah\", \"yahh\", \"yaj\", \"yak\", \"yakw\", \"yal\", \"yam\", \"yan\", \r\n",
        "              \"yaq\", \"yar\",\"yarr\", \"yas\", \"yass\", \"yat\", \"yatt\", \"yaw\", \"yax\", \r\n",
        "              \"yay\", \"yaz\", \"yazz\", \"yey\", \"yi\", \"yu\"] # a list of all possible classes\r\n",
        "\r\n",
        "training_data = [] # a list that will contain processed training data\r\n",
        "testing_data = [] # a list that will contain processed testing data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT29UQrnd5G0"
      },
      "source": [
        "# LOADING UP THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4_nyb6goN6",
        "cellView": "form"
      },
      "source": [
        "\r\n",
        "#@markdown \\\r\n",
        "#@markdown #### Entrez le chemin d'accès au répertoire DATASET dans votre Drive:\r\n",
        "chemin = \"\" #@param {type:\"string\"}\r\n",
        "#@markdown \\\r\n",
        "\r\n",
        "if chemin == \"\":\r\n",
        "    chemin = \"genie info/Rapport PFE - HexaCoders/DATASET\" #default path\r\n",
        "# Variables Declaration\r\n",
        "DIR = os.path.join(\"/content/drive/MyDrive\",chemin) # h the path to the DATASET dir  in your drive\r\n",
        "TRAINDATADIR = os.path.join(DIR,\"training_data/\")\r\n",
        "TESTDATADIR = os.path.join(DIR,\"testing_data/\")\r\n",
        "MODELDIR = os.path.join(DIR,\"model/\")\r\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N_yFjf_qXCP"
      },
      "source": [
        "#### Preparing training data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0S-Vd6uGsYcO"
      },
      "source": [
        "<b>OpenCV</b> (référencé par cv) est une bibliothèque multi-plateforme qui nous permet de développer des applications de vision par ordinateur en temps réel. Elle se concentre principalement sur le traitement des images en temps réel., la capture et l'analyse vidéo, y compris des fonctionnalités telles que la détection des visages et des objets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTDF8xVxkhrs"
      },
      "source": [
        "training_data = [] # a list that will contain processed training data\r\n",
        "def prepare_training_data():\r\n",
        "    for category in CATEGORIES :\r\n",
        "        path = os.path.join(TRAINDATADIR, category)\r\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 to 32)\r\n",
        "        for img in os.listdir(path): # iterate over each image in a caracter folder \r\n",
        "            img_array = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE) # read graysacled images\r\n",
        "            new_array = cv.resize(img_array, (50,50)) # resizing images\r\n",
        "            training_data.append([new_array, class_num]) # append processed image to the training data list\r\n",
        "\r\n",
        "prepare_training_data() # calling the fct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbCC07Y3coSH"
      },
      "source": [
        "Nous voulons mélanger les données. Pour l'instant, nos données ne sont que \"ya\", puis \"yab\", puis \"yach\" ... . Cela finit généralement par causer des problèmes, car, au début, le classificateur apprendra à prédire toujours \"ya\". Ensuite, il passera à prédire tout \"yab\" ..., Faire des allers-retours comme ça n'est pas bon non plus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4nf3AKE7GDh"
      },
      "source": [
        "# shuffle the training data randomly \r\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-_F3RpVwN5d"
      },
      "source": [
        "#### Creating the training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1vgeaDU7fHa"
      },
      "source": [
        "# Create the model\r\n",
        "X = [] \r\n",
        "Y = []\r\n",
        "\r\n",
        "for features,label in training_data:\r\n",
        "    X.append(features)\r\n",
        "    Y.append(label)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeYWj6QXqgeu"
      },
      "source": [
        "#### Saving the training model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4lC8VIOb_kY"
      },
      "source": [
        "Le module <b> pickle </b> met en œuvre des protocoles binaires pour sérialiser et désérialiser une structure d'objet Python. <br><br> Le \"pickling\" est le processus par lequel une hiérarchie d'objets Python est convertie en un flux d'octets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzzQfQdu7rnu"
      },
      "source": [
        "# Saving the model\r\n",
        "\r\n",
        "pickle_out = open(MODELDIR + \"X.pickle\",\"wb\")\r\n",
        "pickle.dump(X, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(MODELDIR + \"Y.pickle\",\"wb\")\r\n",
        "pickle.dump(Y, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9s-a1jwqqQQ"
      },
      "source": [
        "#### Uploading the training model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PRFC3SurZOH"
      },
      "source": [
        "Le \"unpickling\" est l'opération inverse, par laquelle un flux d'octets (provenant d'un fichier binaire ou d'un objet de type octet) est reconverti en une hiérarchie d'objets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8tLrB3_72kp"
      },
      "source": [
        "# to load the model we use the script\r\n",
        "pickle_in = open(MODELDIR + \"X.pickle\",\"rb\")\r\n",
        "X = pickle.load(pickle_in)\r\n",
        "\r\n",
        "pickle_in = open(MODELDIR + \"Y.pickle\",\"rb\")\r\n",
        "Y = pickle.load(pickle_in)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04UMVpJcIDiv"
      },
      "source": [
        "# CREATING THE CONVOLUTIONAL NURAL NETWORK"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM8TPLkXr7Mu"
      },
      "source": [
        "#### CNN Configurations "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUp1KS7HxZRD"
      },
      "source": [
        "# Convolutional Layer 1.\r\n",
        "filter_size1 = 5          # Convolution filters are 5 x 5 pixels.\r\n",
        "num_filters1 = 16         # There are 16 of these filters.\r\n",
        "\r\n",
        "# Convolutional Layer 2.\r\n",
        "filter_size2 = 5          # Convolution filters are 5 x 5 pixels.\r\n",
        "num_filters2 = 36         # There are 36 of these filters.\r\n",
        "\r\n",
        "# Fully-connected layer.\r\n",
        "fc_size = 128             # Number of neurons in fully-connected layer."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9I5wu7iWBicv"
      },
      "source": [
        "#### Data-dimensions for convenience"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2A6pz5O_l0k"
      },
      "source": [
        "# The number of pixels in each dimension of an image.\r\n",
        "img_size = 50\r\n",
        "\r\n",
        "# The images are stored in one-dimensional arrays of this length.\r\n",
        "img_size_flat = 50*50\r\n",
        "\r\n",
        "# Tuple with height and width of images used to reshape arrays.\r\n",
        "img_shape = (50, 50)\r\n",
        "\r\n",
        "# Number of classes, one class for each of 33 alphabet.\r\n",
        "num_classes = 33\r\n",
        "\r\n",
        "# Number of colour channels for the images: 1 channel for gray-scale.\r\n",
        "num_channels = 1"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NaQ6iTWVBtzS"
      },
      "source": [
        "#### Helper-function for plotting images\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBcIZgZKBssY"
      },
      "source": [
        "# TODO\r\n",
        "def plot_image(image, cls_true, cls_pred=None):\r\n",
        "    \r\n",
        "   \r\n",
        "    plt.imshow(images.reshape(img_shape), cmap='gray')\r\n",
        "\r\n",
        "        # Show true and predicted classes.\r\n",
        "    if cls_pred is None:\r\n",
        "        #plt.(.5,.9,'Temperature', fontsize=100, ha='center')\r\n",
        "        plt.figtext(\"True: {0}\".format(cls_true)\r\n",
        "    else:\r\n",
        "        #plt.figtext(.5,.9,'Temperature', fontsize=100, ha='center')\r\n",
        "        plt.figtext = \"True: {0}, Pred: {1}\".format(cls_true, cls_pred)\r\n",
        "        \r\n",
        "    plt.axis('off')\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slZAWTd5B9pJ",
        "outputId": "c45892ad-fc4b-45ab-c4bb-a0fb04492bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        }
      },
      "source": [
        "images = X[1]\r\n",
        "\r\n",
        "# Get the true classes for those images.\r\n",
        "cls_true = Y[1]\r\n",
        "\r\n",
        "# Plot the images and labels using our helper-function above.\r\n",
        "plot_image(image=images, cls_true=cls_true)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfS6X8v0CG6Y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}