{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abderrazzaq-laanoui/PFE-HexaCoders/blob/PreparingData/Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8hCO76eiaTU"
      },
      "source": [
        "<div style=\"text-align:center\"><h1>RECONNAISSANCE DE L'ÉCRITURE MANUSCRITE DE LESTTRES TEFINAGH</h1></div>\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KT29UQrnd5G0"
      },
      "source": [
        "# LOADING UP THE DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCrPAac4eeMo"
      },
      "source": [
        "# mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svq_MDEee7Uk"
      },
      "source": [
        "# import libraries\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vl4_nyb6goN6",
        "cellView": "form"
      },
      "source": [
        "\r\n",
        "#@markdown \\\r\n",
        "#@markdown #### Entrez le chemin d'accès au répertoire DATASET dans votre Drive:\r\n",
        "chemin = \"\" #@param {type:\"string\"}\r\n",
        "#@markdown \\\r\n",
        "\r\n",
        "if chemin == \"\":\r\n",
        "    chemin = \"genie info/Rapport PFE - HexaCoders/DATASET\" #default path\r\n",
        "# Variables Declaration\r\n",
        "DIR = os.path.join(\"/content/drive/MyDrive\",chemin) # h the path to the DATASET dir  in your drive\r\n",
        "TRAINDATADIR = os.path.join(DIR,\"training_data/\")\r\n",
        "TESTDATADIR = os.path.join(DIR,\"testing_data/\")\r\n",
        "MODELDIR = os.path.join(DIR,\"model/\")\r\n",
        "\r\n",
        "CATEGORIES = [\"ya\", \"yab\", \"yach\", \"yad\", \"yadd\", \"yae\", \"yaf\", \"yag\", \"yagh\", \r\n",
        "              \"yagw\", \"yah\", \"yahh\", \"yaj\", \"yak\", \"yakw\", \"yal\", \"yam\", \"yan\", \r\n",
        "              \"yaq\", \"yar\",\"yarr\", \"yas\", \"yass\", \"yat\", \"yatt\", \"yaw\", \"yax\", \r\n",
        "              \"yay\", \"yaz\", \"yazz\", \"yey\", \"yi\", \"yu\"] # a list of all possible classes\r\n",
        "\r\n",
        "training_data = [] # a list that will contain processed training data\r\n",
        "testing_data = [] # a list that will contain processed testing data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTDF8xVxkhrs"
      },
      "source": [
        "def prepare_training_data():\r\n",
        "    i = 0\r\n",
        "    for category in CATEGORIES :\r\n",
        "        path = os.path.join(TRAINDATADIR, category)\r\n",
        "        class_num = CATEGORIES.index(category)  # get the classification  (0 to 32)\r\n",
        "        for img in os.listdir(path): # iterate over each image in a caracter folder \r\n",
        "            img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE) # read graysacled images\r\n",
        "            new_array = cv2.resize(img_array, (50,50)) # resizing images\r\n",
        "            training_data.append([new_array, class_num]) # append processed image to the training data list\r\n",
        "            i+=1\r\n",
        "            dispaly(str(i) \"/25740\") \r\n",
        "            \r\n",
        "prepare_training_data() # calling the fct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbCC07Y3coSH"
      },
      "source": [
        "Nous voulons mélanger les données. Pour l'instant, nos données ne sont que \"ya\", puis \"yab\", puis \"yach\" ... . Cela finit généralement par causer des problèmes aussi, car, au début, le classificateur apprendra à prédire toujours \"ya\". Ensuite, il passera à prédire tout \"yab\" ..., Faire des allers-retours comme ça n'est pas bon non plus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4nf3AKE7GDh"
      },
      "source": [
        "# shuffle the training data randomly \r\n",
        "import random\r\n",
        "random.shuffle(training_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1vgeaDU7fHa"
      },
      "source": [
        "# Create the model\r\n",
        "X = []\r\n",
        "Y = []\r\n",
        "\r\n",
        "for features,label in training_data:\r\n",
        "    X.append(features)\r\n",
        "    Y.append(label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4lC8VIOb_kY"
      },
      "source": [
        "Le module <b> pickle </b> met en œuvre des protocoles binaires pour sérialiser et désérialiser une structure d'objet Python. Le \"pickling\" est le processus par lequel une hiérarchie d'objets Python est convertie en un flux d'octets, et le \"unpickling\" est l'opération inverse, par laquelle un flux d'octets (provenant d'un fichier binaire ou d'un objet de type octet) est reconverti en une hiérarchie d'objets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzzQfQdu7rnu"
      },
      "source": [
        "# Saving the model\r\n",
        "import pickle\r\n",
        "\r\n",
        "pickle_out = open(MODELDIR + \"X.pickle\",\"wb\")\r\n",
        "pickle.dump(X, pickle_out)\r\n",
        "pickle_out.close()\r\n",
        "\r\n",
        "pickle_out = open(MODELDIR + \"Y.pickle\",\"wb\")\r\n",
        "pickle.dump(Y, pickle_out)\r\n",
        "pickle_out.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8tLrB3_72kp"
      },
      "source": [
        "# to load the model we use the script\r\n",
        "pickle_in = open(MODELDIR + \"X.pickle\",\"rb\")\r\n",
        "X = pickle.load(pickle_in)\r\n",
        "\r\n",
        "pickle_in = open(MODELDIR + \"Y.pickle\",\"rb\")\r\n",
        "Y = pickle.load(pickle_in)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}